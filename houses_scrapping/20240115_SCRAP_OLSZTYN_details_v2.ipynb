{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf283ed7",
   "metadata": {},
   "source": [
    "# OLSZTYN\n",
    "- scraping details \n",
    "- DATE 2024 jan 15th - this is done using URLs downloaded on the 4th of January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a617cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x1d849c57348>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# prepering directories\n",
    "path = os.getcwd()\n",
    "# subfolders\n",
    "input_dir = os.path.join(path, 'inputs')\n",
    "output_dir = os.path.join(path, 'outputs')\n",
    "\n",
    "# open folder\n",
    "subprocess.Popen(f'explorer \"{output_dir}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23714de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Ukasz\\Anaconda3\\envs\\geopandas\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# selenium \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d756e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'olsztyn_page_all_pages_20240106151418.csv'\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), 'outputs', data))\n",
    "df = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605dceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome driver location\n",
    "PATH = os.path.join(path, 'inputs','chromedriver.exe' )\n",
    "\n",
    "# chrom driver configuration\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "#options.add_argument('--headless') # without opening browser\n",
    "\n",
    "driver = webdriver.Chrome(PATH, options=options)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9bb8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url \n",
    "url = 'https://www.otodom.pl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6347ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...1 Expired...2...3...4..."
     ]
    }
   ],
   "source": [
    "not_scraped = []\n",
    "top_tags = ['Powierzchnia','Forma własności','Liczba pokoi','Stan wykończenia','Piętro','Balkon / ogród / taras','Czynsz','Miejsce parkingowe','Obsługa zdalna','Ogrzewanie']\n",
    "bottom_tags = ['Rynek', 'Typ ogłoszeniodawcy', 'Dostępne od','Rok budowy','Rodzaj zabudowy','Okna','Winda','Media','Zabezpieczenia','Wyposażenie','Informacje dodatkowe','Materiał budynku']\n",
    "\n",
    "def accept_terms():\n",
    "    # accepting terms and conditions\n",
    "    # this has to be done only once\n",
    "    element = wait.until(EC.element_to_be_clickable((By.ID, 'onetrust-pc-btn-handler')))\n",
    "    element.click()\n",
    "    # step two -  confirming preferences and closing the modal window\n",
    "    element = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[contains(text(), 'Potwierdzenie moich wyborów')]\")))\n",
    "    element.click()\n",
    "    \n",
    "    \n",
    "def get_data(soup):\n",
    "    data = {}\n",
    "    top_information = soup.find('div', attrs={'data-testid':'ad.top-information.table'})\n",
    "    bottom_information = soup.find('div', attrs={'data-testid':'ad.additional-information.table'})\n",
    "       \n",
    "    for tag in top_tags:\n",
    "        try:\n",
    "            div_tag = top_information.find('div', attrs={'aria-label':tag})\n",
    "            results = div_tag.find_all(\"div\")\n",
    "            data[tag] = results[2].text\n",
    "        except:\n",
    "            data[tag] = results[2].text\n",
    "            \n",
    "    for tag in bottom_tags:\n",
    "        try:\n",
    "            div_tag = bottom_information.find('div', attrs={'aria-label':tag})\n",
    "            results = div_tag.find_all(\"div\")\n",
    "            data[tag] = results[2].text\n",
    "        except:\n",
    "            data[tag] = results[2].text\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def save_data(i, data, out_df, date):\n",
    "    \n",
    "    for k in data:\n",
    "        out_df.loc[i, k] = data[k]\n",
    "    out_df.to_csv(os.path.join(path, 'outputs', f'{date}olsztyn_details.csv'), encoding='utf-8')\n",
    "\n",
    "    \n",
    "expired = 0\n",
    "for i in list(df.index):\n",
    "    date = datetime.datetime.now().strftime(\"%Y%m%d\") # current date\n",
    "    link = df['add_link'][i]\n",
    "    # open website using webdriver\n",
    "    driver.get(url + link)\n",
    "    if i == 0:\n",
    "        out_df = df.copy()\n",
    "        out_df.to_csv(os.path.join(path, 'outputs', f'{date}olsztyn_details.csv'), encoding='utf-8')\n",
    "        accept_terms()\n",
    "    \n",
    "    time.sleep(2) # waits n seconds  \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    if soup.findAll(text=\"To ogłoszenie jest już niedostępne\"):\n",
    "        expired += 1\n",
    "        print(f'{i} Expired', end='...')\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        data = get_data(soup)\n",
    "        if i > 0:\n",
    "            out_df = pd.read_csv(os.path.join(os.getcwd(), 'outputs', f'{date}olsztyn_details.csv'), encoding='utf-8')   \n",
    "        save_data(i, data, out_df, date)\n",
    "        print(i, end='...')\n",
    "    except:\n",
    "        not_scraped.append(i)\n",
    "        print(f'{i} Issue', end='...')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af0d92a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 'baz.py', 'bar.py', 'foo.py', 'qux.py', Ellipsis]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 'baz.py', 'bar.py', 'foo.py', 'qux.py', Ellipsis]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 'baz.py', 'bar.py', 'foo.py', 'qux.py', Ellipsis]\n",
      "[3, 4, 5, 6, 7, 8, 9, 'baz.py', 'bar.py', 'foo.py', 'qux.py', Ellipsis]\n",
      "[4, 5, 6, 7, 8, 9, 'baz.py', 'bar.py', 'foo.py', 'qux.py', Ellipsis]\n",
      "[5, 6, 7, 8, 9, 'baz.py', 'bar.py', 'foo.py', 'qux.py', Ellipsis]\n",
      "[6, 7, 8, 9, 'baz.py', 'bar.py', 'foo.py', 'qux.py', Ellipsis]\n",
      "[7, 8, 9, 'baz.py', 'bar.py', 'foo.py', 'qux.py', Ellipsis]\n",
      "['foo.py', 'baz.py', Ellipsis, 8, 9, 'qux.py', 'bar.py']\n",
      "['baz.py', Ellipsis, 'foo.py', 9, 'qux.py', 'bar.py']\n",
      "[Ellipsis, 'foo.py', 'baz.py', 'qux.py', 'bar.py']\n",
      "['foo.py', 'qux.py', Ellipsis, 'bar.py']\n",
      "['foo.py', 'qux.py', Ellipsis]\n",
      "['qux.py', Ellipsis]\n",
      "[Ellipsis]\n"
     ]
    }
   ],
   "source": [
    "not_scraped = set(list(range(10))) \n",
    "to_do = set ( ['foo.py', 'bar.py', 'baz.py', 'qux.py', Ellipsis] )\n",
    "\n",
    "while list(not_scraped.union(to_do)):\n",
    "    for i in list(not_scraped.union(to_do)):\n",
    "        print(list(not_scraped.union(to_do)))\n",
    "        if i in not_scraped:\n",
    "            not_scraped.remove(i)\n",
    "        if i in to_do:\n",
    "            to_do.remove(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bf286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805322d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
